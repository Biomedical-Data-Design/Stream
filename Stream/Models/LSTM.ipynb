{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eba_S3Wm_u7P",
        "outputId": "67e8b4a7-0647-419a-efbc-73b9f863ebac"
      },
      "outputs": [],
      "source": [
        "# comment if not using google colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# import os\n",
        "# os.chdir('/content/drive/My Drive/LSTM')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZbeXE3flXDJ"
      },
      "outputs": [],
      "source": [
        "# define seed\n",
        "def seed_everything(seed=3407): # The torch.manual_seed(3407) is all you need! lol\n",
        "    \"\"\"\n",
        "    Seed everything to make all operations in PyTorch (and other libraries) deterministic.\n",
        "    Args:\n",
        "        seed (int): Seed value to set.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLbr8JTL_wU0",
        "outputId": "7abc396c-60bf-4c43-d0d4-706621c0cd47"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "log_dir = './Result/untitled5/round13/'\n",
        "\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "tic = time.time()\n",
        "\n",
        "seed_everything()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "print(f'Currently Using device: {device}')\n",
        "\n",
        "acc_list = []\n",
        "\n",
        "for z in range(5):\n",
        "  print('='*20)\n",
        "  print(f'Training of Fold {z+1}')\n",
        "  print('='*20)\n",
        "\n",
        "  filename = f'balanced_LSTM_long{z+1}.csv'\n",
        "  print(f'Filename: {filename}')\n",
        "  data = pd.read_csv(filename)\n",
        "  \n",
        "  feature_columns = [col for col in data.columns if col not in ('patientunitstayid', 'observationoffset', 'actualicumortality')]\n",
        "  label_column = 'actualicumortality'\n",
        "\n",
        "  # initialize lists\n",
        "  sequences = []\n",
        "  labels = []\n",
        "\n",
        "  for _, group in data.groupby('patientunitstayid'):\n",
        "    sequence = torch.tensor(group[feature_columns].values, dtype=torch.float)\n",
        "    sequences.append(sequence)\n",
        "    labels.append(group[label_column].iloc[0])\n",
        "\n",
        "  # pad sequences & convert to tensor\n",
        "  padded_sequences = pad_sequence(sequences, batch_first=True).to(device)\n",
        "  # print(padded_sequences.shape)\n",
        "  labels = torch.tensor(labels, dtype=torch.float).to(device)\n",
        "  lengths = torch.tensor([len(seq) for seq in sequences]).to(device)\n",
        "\n",
        "  # train-test split\n",
        "  X_train, X_test, L_train, L_test, y_train, y_test = train_test_split(padded_sequences, lengths, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "  # minus 1 in time length\n",
        "  L_test -= 1\n",
        "  L_train -= 1\n",
        "  \n",
        "  # create dataloaders\n",
        "  train_dataset = TensorDataset(X_train, L_train, y_train)\n",
        "  train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "  test_dataset = TensorDataset(X_test, L_test, y_test)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "  # define LSTM model\n",
        "  class TraditionalLSTM(nn.Module):\n",
        "      def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(TraditionalLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "      def forward(self, input_seq, input_lengths):\n",
        "        # Pack padded sequence\n",
        "        packed_input = pack_padded_sequence(input_seq, input_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        packed_output, (h, c) = self.lstm(packed_input)\n",
        "\n",
        "        # Unpack output\n",
        "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "\n",
        "        idx = (input_lengths - 1).view(-1, 1).expand(len(input_lengths), output.size(2)).unsqueeze(1).to(device)\n",
        "        last_output = output.gather(1, idx).squeeze(1)\n",
        "\n",
        "        final_output = self.fc(last_output)\n",
        "        final_output = self.sigmoid(final_output)\n",
        "        return final_output\n",
        "\n",
        "  # initializ\n",
        "  input_size = 13\n",
        "  hidden_size = 100\n",
        "  output_size = 1\n",
        "\n",
        "  model = TraditionalLSTM(input_size, hidden_size, output_size).to(device)\n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "  # Train\n",
        "  num_epochs = 40\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for sequences, lengths, labels in train_loader:\n",
        "        sequences, lengths, labels = sequences.to(device), lengths.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(sequences, lengths)\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # Test\n",
        "    if epoch % 5 == 4:\n",
        "      model.eval()\n",
        "      predicted_labels_eval = []\n",
        "      true_labels_eval = []\n",
        "      with torch.no_grad():\n",
        "        for sequences, lengths, labels in test_loader:\n",
        "            sequences, lengths, labels = sequences.to(device), lengths.to(device), labels.to(device)\n",
        "            outputs = model(sequences, lengths)\n",
        "            predicted_labels_eval.extend(outputs.cpu().numpy().flatten())\n",
        "            true_labels_eval.extend(labels.cpu().numpy().flatten())\n",
        "      predicted_labels_eval = [1 if x >= 0.5 else 0 for x in predicted_labels_eval]\n",
        "      accuracy = accuracy_score(true_labels_eval, predicted_labels_eval) * 100\n",
        "      print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
        "    else:\n",
        "      print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}')\n",
        "\n",
        "  # Eval\n",
        "  model.eval()\n",
        "  predicted_labels = []\n",
        "  true_labels = []\n",
        "  predicted_probs = []\n",
        "  with torch.no_grad():\n",
        "    for sequences, lengths, labels in test_loader:\n",
        "        sequences, lengths, labels = sequences.to(device), lengths.to(device), labels.to(device)\n",
        "        outputs = model(sequences, lengths)\n",
        "        predicted_probs.extend(outputs.cpu().numpy().flatten())\n",
        "        predicted_labels.extend(outputs.cpu().numpy().flatten())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "  # save predicted_labels\n",
        "  results_path = os.path.join(log_dir, f'predicted_labels_fold{z+1}.npy')\n",
        "  np.save(results_path, predicted_labels)\n",
        "  # save true_labels\n",
        "  results_path = os.path.join(log_dir, f'true_labels_fold{z+1}.npy')\n",
        "  np.save(results_path, true_labels)\n",
        "  # save model\n",
        "  results_path = os.path.join(log_dir, f'model_fold{z+1}.pth')\n",
        "  torch.save(model.state_dict(), results_path)\n",
        "\n",
        "  from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "  predicted_labels = [1 if x >= 0.5 else 0 for x in predicted_labels]\n",
        "  accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "  print(f'Accuracy: {accuracy}')\n",
        "  acc_list.append(accuracy)\n",
        "\n",
        "  precision = precision_score(true_labels, predicted_labels)\n",
        "  print(f'Precision: {precision}')\n",
        "\n",
        "  recall = recall_score(true_labels, predicted_labels)\n",
        "  print(f'Recall: {recall}')\n",
        "\n",
        "  f1 = f1_score(true_labels, predicted_labels)\n",
        "  print(f'F1 Score: {f1}')\n",
        "\n",
        "  conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "  print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "\n",
        "  # ROC\n",
        "  fpr, tpr, thresholds = roc_curve(true_labels, predicted_probs)\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "  plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.0])\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Receiver Operating Characteristic')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.savefig(os.path.join(log_dir, f'roc_curve_fold{z+1}.png'))\n",
        "  plt.show()\n",
        "\n",
        "print(f'Accuracy: {acc_list}')\n",
        "print(f'avg_Acc:{np.mean(acc_list)}')\n",
        "\n",
        "toc = time.time()\n",
        "print(f'Time taken: {toc - tic:0.4f} seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROC for all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "true_labels = []\n",
        "\n",
        "for z in range(5):\n",
        "    predicted_path = os.path.join(log_dir, f'predicted_labels_fold{z+1}.npy')\n",
        "    true_path = os.path.join(log_dir, f'true_labels_fold{z+1}.npy')\n",
        "    predicted_labels.append(np.load(predicted_path))\n",
        "    true_labels.append(np.load(true_path))\n",
        "predicted_labels = np.concatenate(predicted_labels)\n",
        "true_labels = np.concatenate(true_labels)\n",
        "fpr, tpr, thresholds = roc_curve(true_labels, predicted_labels)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure()\n",
        "\n",
        "# # Optimal Threshold\n",
        "# closest_zero_one_point = np.argmin(np.sqrt((fpr - 0)**2 + (tpr - 1)**2))\n",
        "# closest_fpr = fpr[closest_zero_one_point]\n",
        "# closest_tpr = tpr[closest_zero_one_point]\n",
        "# closest_threshold = thresholds[closest_zero_one_point]\n",
        "# plt.scatter(closest_fpr, closest_tpr, marker='o', color='red', label='Optimal Threshold')\n",
        "\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(os.path.join(log_dir, f'roc_curve_total.svg'))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
